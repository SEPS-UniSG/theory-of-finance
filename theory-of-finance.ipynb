{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Theory_of_Finance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdyvJeeEtF2E"
      },
      "source": [
        "# Theory of Finance\n",
        "\n",
        "In this notebook, you will work with stock market data from the S&P500. You will learn some basics of portfolio management using Python, such as computing log-returns, computing and plotting the mean-variance frontier, and building the minimum variance portfolio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQS7qBMkg-Ed"
      },
      "source": [
        "# Library to access Yahoo!Finance data through Python\n",
        "import pandas_datareader.data as pdata\n",
        "# Numerical computation library\n",
        "import numpy as np\n",
        "# Plotting library\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWN-jthuh8_h"
      },
      "source": [
        "## Obtaining financial data\n",
        "\n",
        "The first thing we are going to do is gather stock prices from the `pandas-datareader` package we have just loaded above. In general, there exist a lot of different sources for financial data, depending on your requirements (which markets, which frequency, which time window, etc.) you might need to look into further sources. For simplicity's sake, this notebook will ignore these complications but these are things you should connsider when writing your research.\n",
        "\n",
        "\n",
        "We begin by building a list of 30 *random* tickers from stocks in the S&P500. We will grab the data from pandas-datareader for these stocks only.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6teoMLHt2yY"
      },
      "source": [
        "# Create a list with the tickers of the stocks for which we want to obtain data\n",
        "stocklist = ['AAPL', 'AFL', 'AMZN', 'APD', 'BAC', 'COF', 'COST', \n",
        "             'HBAN', 'HON', 'INTU', 'IPG', 'KEY', 'KLAC', 'LMT', \n",
        "             'LOW', 'MSFT', 'NEM', 'NKE', 'OMC', 'PAYX', 'RF', 'RHI', \n",
        "             'SNA', 'SWK', 'UPS', 'USB', 'VZ', 'WHR', 'WY', 'YUM']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvuTXT2IvDo8"
      },
      "source": [
        "Because we are querying an online API, obtaining the data can take a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ycWDIbh2Dj"
      },
      "source": [
        "# Obtain the data from Yahoo!Finance between 1st Jan 2010 and 1st Jun 2021\n",
        "prices = pdata.DataReader(stocklist, data_source = 'yahoo', \n",
        "                          start = '2010-1-1', end = '2021-6-1')\n",
        "# Keep only the \"Adjusted Close\" prices\n",
        "prices = prices[\"Adj Close\"]\n",
        "# Display the first 10 rows of the dataset\n",
        "prices.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EhENz7PmZVY"
      },
      "source": [
        "# Create a dataframe of percentage returns\n",
        "returns = 100 * prices.pct_change()\n",
        "# Display the first 10 rows\n",
        "returns.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMcyMDF-vWYE"
      },
      "source": [
        "Now that we have obtained stock returns for our 30 stocks between 2010 and 2021, we further proceed by splitting the data into train and test sets. In general, a train set is a set you use to fit your model and the test set is used to validate your model. This can help us understand when a model is overfitting. An overfitted model will perform well on the train data (the data that was used to fit the model) and it will perform badly on the test set (data that the model has not \"*seen*\" yet)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upjKw1rfmZX9"
      },
      "source": [
        "# Separate the data into a training (pre-2020) and a testing set (post-2019)\n",
        "train_index = returns.index < \"2020-1-1\"\n",
        "test_index = returns.index >= \"2020-1-1\"\n",
        "returns[train_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJywAELToXAT"
      },
      "source": [
        "# Using the training set, compute the stock returns means,\n",
        "mean_returns = returns[train_index].mean()\n",
        "# ... standard deviations,\n",
        "std_returns  = returns[train_index].std()\n",
        "# ... and covariances\n",
        "cov_returns = returns[train_index].cov()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltbHQbskxIpR"
      },
      "source": [
        "## Computing the efficient frontier\n",
        "\n",
        "The efficient frontier (also mean-variance or portfolio frontier) is a set of portfolio allocations which offer the lowest variance for a given level of return.\n",
        "\n",
        "Finding the efficient frontier is done by solving the optimization problem\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\min &\\mathbb{V}[R_p] \\\\ \\text{s.t.} \\ &\\mathbb{E}[R_p] = \\mu^\\star\n",
        "\\end{align}\n",
        "$$\n",
        "where $\\mathbb{V}[R_p]$ represents the variance of the portfolio and $\\mathbb{E}[R_p]$ its expected value. Additionally, it is imperative that the chosen portfolio sum to 1.\n",
        "\n",
        "The efficient frontier can be obtained through numerical minimization or by linear algebra, we follow the latter approach, as given in https://github.com/PaulSoderlind/FinancialTheoryMSc/blob/master/Ch03_MeanVariance.ipynb (however, the linked notebook implements the approach in Julia, here it is of course done in Python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT4VcRlPyz7e"
      },
      "source": [
        "# Compute the efficient frontier\n",
        "I = np.ones(mean_returns.shape)   # Vector of ones\n",
        "S_1 = np.linalg.inv(cov_returns)  # Inverse of the return covariance matrix\n",
        "# Compute scalars to help us with the computation of the frontier \n",
        "# (see course slides, chapter 3.1.4)\n",
        "A = np.transpose(mean_returns) @ S_1 @ mean_returns\n",
        "B = np.transpose(mean_returns) @ S_1 @ I\n",
        "C = np.transpose(I) @ S_1 @ I\n",
        "# Create a function that returns the weights that minimize the variance for a \n",
        "# given level of returns mu_star\n",
        "def mv_frontier(mu_star):\n",
        "  lam = (C * mu_star - B) / (A * C - B**2)\n",
        "  delta = (A - B * mu_star) / (A * C - B**2)\n",
        "  w = S_1 @ (mean_returns * lam + I * delta)\n",
        "  return np.sqrt(np.transpose(w) @ cov_returns @ w), w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_jY0VFphfH"
      },
      "source": [
        "# Create a mean-variance diagram for stock returns\n",
        "fig, ax = plt.subplots(figsize = (14, 10))\n",
        "# Plot a scatterplot of returns' mean/stdev points for each stock\n",
        "ax.plot(std_returns, mean_returns, 'o')\n",
        "# Plot the mean-variance frontier\n",
        "mu_star = np.arange(0, 0.2, step = 0.001)\n",
        "ax.plot(np.vectorize(lambda x: mv_frontier(x)[0])(mu_star), mu_star)\n",
        "# Add ticker annotations\n",
        "for tic in mean_returns.index:\n",
        "  ax.annotate(tic, xy = (std_returns[tic], mean_returns[tic]), size = 8)\n",
        "ax.set_xlabel(\"Standard deviation\")        # Set x-axis label\n",
        "ax.set_ylabel(\"Mean\")                      # Set y-axis label\n",
        "ax.set_title(\"Returns' mean-stdev plot\")   # Set title of the plot\n",
        "plt.show()                                 # Display the plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxEQ8UKH1Q48"
      },
      "source": [
        "## Comparing portfolios\n",
        "\n",
        "We now compute the weights that produce the minimum variance portfolio on the train set. Using the equal weights portfolio as a benchmark, we compare the performance of both portfolios on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Z1f-IxDHAy"
      },
      "source": [
        "# Compute the min-variance portfolio weights\n",
        "w_minvar = (S_1 @ I) / (np.transpose(I) @ S_1 @ I)\n",
        "# Store uniform weights for a benchmark portfolio\n",
        "w_uniform = np.ones(prices.shape[1]) / prices.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXaemFK1_2vB"
      },
      "source": [
        "# Create a function to return an array of portfolio value over time\n",
        "def portfolio_value(prices, weights):\n",
        "  # Compute the logarithmic returns\n",
        "  log_returns = np.log(prices) - np.log(prices.shift(1))\n",
        "  # Multiply the log returns by the associated weights, take the cumulative sum\n",
        "  # and exponentiate to transform back to percentage returns\n",
        "  return np.exp(np.cumsum(np.sum(weights * log_returns, axis = 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1FHbVjQ5QDz"
      },
      "source": [
        "# Compute the returns for both portfolios for the train and test set\n",
        "r_minvar_train = portfolio_value(prices[train_index], w_minvar)\n",
        "r_uniform_train = portfolio_value(prices[train_index], w_uniform)\n",
        "r_minvar_test = portfolio_value(prices[test_index], w_minvar)\n",
        "r_uniform_test = portfolio_value(prices[test_index], w_uniform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jwxj_tW3DnN"
      },
      "source": [
        "# Create a plot of portfolio value over time\n",
        "fig, ax = plt.subplots(2, figsize = (14, 16))\n",
        "# Create the plot for the train set\n",
        "ax[0].plot(r_minvar_train, label='Min-variance')\n",
        "ax[0].plot(r_uniform_train, label='Equal weights')\n",
        "ax[0].set_xlabel(\"Date\")            # Set x-axis label\n",
        "ax[0].set_ylabel(\"Portfolio value\") # Set y-axis label\n",
        "ax[0].set_title(\"Train set\")        # Set title of the plot\n",
        "ax[0].grid()                        # Add a grid\n",
        "ax[0].legend(loc='best')            # Add the legend\n",
        "# Create the plot for the test set\n",
        "ax[1].plot(r_minvar_test, label='Min-variance')\n",
        "ax[1].plot(r_uniform_test, label='Equal weights')\n",
        "ax[1].set_xlabel(\"Date\")            # Set x-axis label\n",
        "ax[1].set_ylabel(\"Portfolio value\") # Set y-axis label\n",
        "ax[1].set_title(\"Test set\")         # Set title of the plot\n",
        "ax[1].grid()                        # Add a grid\n",
        "ax[1].legend(loc='best')            # Add the legend\n",
        "plt.show()                          # Display the plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPUpZQY63op"
      },
      "source": [
        "We see that, for both the train and test data, the equally weighted portfolio outperforms the minimum-variance portfolio returns-wise, however, it is also quite obvious that its variance is much higher.\n",
        "\n",
        "To get a better grasp of these differences, we compute the mean, standard deviation, and Sharpe ratio of both portfolios for both the train and test period.\n",
        "\n",
        "Because computing means of percentage returns does not make sense, we will instead work with log-returns for the portfolio metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsNMZO7i8zat"
      },
      "source": [
        "# Create a function to output portfolio metrics\n",
        "def portfolio_metrics(prices, weights):\n",
        "  # Compute the logarithmic returns\n",
        "  log_returns = np.log(prices) - np.log(prices.shift(1))\n",
        "  # Compute the log-returns for the portfolio\n",
        "  log_returns = np.sum(weights * log_returns, axis = 1)\n",
        "  # Compute and display the portfolio metrics\n",
        "  mu = np.mean(log_returns)\n",
        "  sigma = np.std(log_returns)\n",
        "  print(\"Mean:    \", round(mu, 5))\n",
        "  print(\"St. dev.:\", round(sigma, 5))\n",
        "  print(\"Sharpe:  \", round(mu/sigma, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YETDqpR17nUg"
      },
      "source": [
        "print(\"Min. variance portfolio (train data)\")\n",
        "print(\"-----------------------------------------\")\n",
        "portfolio_metrics(prices[train_index], w_minvar)\n",
        "print(\"\") # Empty line\n",
        "print(\"Equally weighted portfolio (train data)\")\n",
        "print(\"-----------------------------------------\")\n",
        "portfolio_metrics(prices[train_index], w_uniform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p325IUIA--G6"
      },
      "source": [
        "print(\"Min. variance portfolio (test data)\")\n",
        "print(\"-----------------------------------------\")\n",
        "portfolio_metrics(prices[test_index], w_minvar)\n",
        "print(\"\") # Empty line\n",
        "print(\"Equally weighted portfolio (test data)\")\n",
        "print(\"-----------------------------------------\")\n",
        "portfolio_metrics(prices[test_index], w_uniform)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}